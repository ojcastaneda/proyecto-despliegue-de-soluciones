{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03388890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ./humor-detection ipywidgets==8.1.5 --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149d54f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from humor_detection.encoder import classification_model, detection_model, load_model\n",
    "from humor_detection.test import test_classification, test_detection\n",
    "from humor_detection.train import train_classification, train_detection\n",
    "from humor_detection.predict import predict_classification, predict_detection\n",
    "from humor_detection.utils import set_random_seeds\n",
    "from IPython.display import display\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "# Nombre del modelo en HuggingFace\n",
    "model_name = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "# Carpeta para agrupar y guardar modelos de clasificación y detección\n",
    "save_path = \"./models/distilbert\"\n",
    "# Argumentos que nunca van a cambiar en entrenamiento/pruebas, dependen de sus GPUs\n",
    "default_arguments = {\n",
    "    \"bf16\": True,\n",
    "    \"bf16_full_eval\": True,\n",
    "    \"disable_tqdm\": False,\n",
    "    \"per_device_eval_batch_size\": 150,\n",
    "    \"per_device_train_batch_size\": 150,\n",
    "}\n",
    "# Prompts para predicciones\n",
    "prompts = [\n",
    "    \"¿Cuál es el último animal que subió al arca de Noé? El del-fin.\",  # Humor\n",
    "    \"El otro día unas chicas llamarón a mi puerta y me pidieron una pequeña donación para una piscina local.\\nLes di un garrafa de agua.\",  # Humor\n",
    "    \"The brain surgeon changed my life. He really opened my mind.\",  # No humor\n",
    "    \"djasndoasndoa\",  # No humor\n",
    "    \"jajaja\",  # No humor\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b06aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea de clasificación 1 a 5 (Los labels son 0 a 4).\n",
    "def run_classification(full_dataset: bool):\n",
    "    # Si bien al importar ya se ejecuta este llamado, cuando de usa jupyter es necesario llamarlo en cada celda\n",
    "    set_random_seeds()\n",
    "    # Función para crear el modelo, tokenizador y añadir un lora si es necesario\n",
    "    model, tokenizer = classification_model(model_name)\n",
    "    # Ajustes de trainer de Transformers https://huggingface.co/docs/transformers/v4.51.3/en/main_classes/trainer#transformers.TrainingArguments\n",
    "    #  Lo más importante es usar bf16 o fp16 para VRAM, batch_sizes para la velocidad y train_epochs para los epochs\n",
    "    arguments = TrainingArguments(\n",
    "        num_train_epochs=10,\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        max_grad_norm=0.01,\n",
    "        **default_arguments,\n",
    "    )\n",
    "    # Entrenamiento con datos en español, Con full_dataset=True entrenan el modelo final, english_data=True añade el dataset en inglés\n",
    "    train_logs, metrics = train_classification(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        arguments,\n",
    "        full_dataset=full_dataset,  # Entrenamiento final\n",
    "        english_data=False,  # Usar dataset de StupidStuff (esto se va a remover con las traducciones)\n",
    "        class_weights=[1, 1.25, 1.25, 2, 4],  # Pesos de clases para desbalance\n",
    "        sample=False,  # Parámetro par \"under\" o \"over\" sample, por el momento no se puede modificar el factor de mágnitud así que no da buenos resultados,\n",
    "        best_model_metric=\"macro_f1\",  # \"macro_f1\" por defecto, \"weighted_f1\" o \"accuracy\" para guardar el mejor epoch del modelo con la mejor métrica seleccionada\n",
    "        save_path=(\n",
    "            f\"{save_path}/classification\" if full_dataset else None\n",
    "        ),  # Dónde guardar los logs de entrenamiento y el modelo final entrenado, puede ser None si no es necesario\n",
    "    )\n",
    "    display(train_logs)\n",
    "    display(metrics)\n",
    "    # Función para cargar el modelo guardado\n",
    "    model, _ = load_model(model_name, f\"{save_path}/classification\")\n",
    "    if not full_dataset:\n",
    "        # Recolección de datos de test con dataset hecho por nosotros en el caso de full_dataset ya se hace en train\n",
    "        display(test_classification(model, tokenizer, arguments))\n",
    "    # Predicción manual de prompts\n",
    "    display(predict_classification(model, tokenizer, prompts, arguments))\n",
    "    # Función para guardar el modelo manualmente (Borra las carpetas antiguas por lo que puede eliminar las métricas)\n",
    "    # save_model(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084379f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e608a5d79c384ded91068d0bb4fa2f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9234 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be60a3bc58d645ffba033055ac168248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 02:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>0 Precision</th>\n",
       "      <th>0 Recall</th>\n",
       "      <th>0 F1-score</th>\n",
       "      <th>0 Support</th>\n",
       "      <th>1 Precision</th>\n",
       "      <th>1 Recall</th>\n",
       "      <th>1 F1-score</th>\n",
       "      <th>1 Support</th>\n",
       "      <th>2 Precision</th>\n",
       "      <th>2 Recall</th>\n",
       "      <th>2 F1-score</th>\n",
       "      <th>2 Support</th>\n",
       "      <th>3 Precision</th>\n",
       "      <th>3 Recall</th>\n",
       "      <th>3 F1-score</th>\n",
       "      <th>3 Support</th>\n",
       "      <th>4 Precision</th>\n",
       "      <th>4 Recall</th>\n",
       "      <th>4 F1-score</th>\n",
       "      <th>4 Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Avg Precision</th>\n",
       "      <th>Macro Avg Recall</th>\n",
       "      <th>Macro Avg F1-score</th>\n",
       "      <th>Macro Avg Support</th>\n",
       "      <th>Weighted Avg Precision</th>\n",
       "      <th>Weighted Avg Recall</th>\n",
       "      <th>Weighted Avg F1-score</th>\n",
       "      <th>Weighted Avg Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.569100</td>\n",
       "      <td>1.495356</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.300529</td>\n",
       "      <td>0.791086</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.326825</td>\n",
       "      <td>0.171614</td>\n",
       "      <td>0.197580</td>\n",
       "      <td>0.142612</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.309592</td>\n",
       "      <td>0.326825</td>\n",
       "      <td>0.253040</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.552100</td>\n",
       "      <td>1.620178</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.121154</td>\n",
       "      <td>0.199367</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.047354</td>\n",
       "      <td>0.076577</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.855856</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.229202</td>\n",
       "      <td>0.191355</td>\n",
       "      <td>0.204873</td>\n",
       "      <td>0.118522</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.345865</td>\n",
       "      <td>0.229202</td>\n",
       "      <td>0.171020</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.469400</td>\n",
       "      <td>1.653001</td>\n",
       "      <td>0.513966</td>\n",
       "      <td>0.176923</td>\n",
       "      <td>0.263233</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.288703</td>\n",
       "      <td>0.384401</td>\n",
       "      <td>0.329749</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.195545</td>\n",
       "      <td>0.355856</td>\n",
       "      <td>0.252396</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.264007</td>\n",
       "      <td>0.206481</td>\n",
       "      <td>0.203180</td>\n",
       "      <td>0.178016</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.352824</td>\n",
       "      <td>0.264007</td>\n",
       "      <td>0.265437</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.282600</td>\n",
       "      <td>1.782049</td>\n",
       "      <td>0.497696</td>\n",
       "      <td>0.207692</td>\n",
       "      <td>0.293080</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.259053</td>\n",
       "      <td>0.256552</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.216606</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.240481</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.238540</td>\n",
       "      <td>0.215006</td>\n",
       "      <td>0.236121</td>\n",
       "      <td>0.192408</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.342073</td>\n",
       "      <td>0.238540</td>\n",
       "      <td>0.259508</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.065400</td>\n",
       "      <td>1.954202</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.163462</td>\n",
       "      <td>0.247813</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.252226</td>\n",
       "      <td>0.236769</td>\n",
       "      <td>0.244253</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.190065</td>\n",
       "      <td>0.396396</td>\n",
       "      <td>0.256934</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.118143</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.231749</td>\n",
       "      <td>0.212147</td>\n",
       "      <td>0.219069</td>\n",
       "      <td>0.181121</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.343463</td>\n",
       "      <td>0.231749</td>\n",
       "      <td>0.239160</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.887800</td>\n",
       "      <td>2.034287</td>\n",
       "      <td>0.520179</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.312248</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.266839</td>\n",
       "      <td>0.286908</td>\n",
       "      <td>0.276510</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.226766</td>\n",
       "      <td>0.274775</td>\n",
       "      <td>0.248473</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.077220</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.256367</td>\n",
       "      <td>0.227957</td>\n",
       "      <td>0.251824</td>\n",
       "      <td>0.207232</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.358434</td>\n",
       "      <td>0.256367</td>\n",
       "      <td>0.276509</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.255198</td>\n",
       "      <td>0.502283</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.253687</td>\n",
       "      <td>0.239554</td>\n",
       "      <td>0.246418</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.231034</td>\n",
       "      <td>0.301802</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.081181</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.130952</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.243633</td>\n",
       "      <td>0.220417</td>\n",
       "      <td>0.251605</td>\n",
       "      <td>0.198625</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.347397</td>\n",
       "      <td>0.243633</td>\n",
       "      <td>0.263631</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.657100</td>\n",
       "      <td>2.271823</td>\n",
       "      <td>0.486034</td>\n",
       "      <td>0.167308</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.274648</td>\n",
       "      <td>0.325905</td>\n",
       "      <td>0.298089</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.260434</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.252122</td>\n",
       "      <td>0.219039</td>\n",
       "      <td>0.228656</td>\n",
       "      <td>0.196945</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.342138</td>\n",
       "      <td>0.252122</td>\n",
       "      <td>0.256862</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.607800</td>\n",
       "      <td>2.381421</td>\n",
       "      <td>0.508380</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.260372</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.266484</td>\n",
       "      <td>0.270195</td>\n",
       "      <td>0.268326</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.216049</td>\n",
       "      <td>0.315315</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.072993</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.117994</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.218187</td>\n",
       "      <td>0.230307</td>\n",
       "      <td>0.188784</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.350643</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.251957</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>2.364112</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.182692</td>\n",
       "      <td>0.268741</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.267760</td>\n",
       "      <td>0.272981</td>\n",
       "      <td>0.270345</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.213650</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.257603</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.126183</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.242784</td>\n",
       "      <td>0.219315</td>\n",
       "      <td>0.234205</td>\n",
       "      <td>0.192908</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.350780</td>\n",
       "      <td>0.242784</td>\n",
       "      <td>0.256952</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 10:59:56 INFO mlflow.tracking.fluent: Experiment with name 'test_distilbert/distilbert-base-multilingual-cased' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5691</td>\n",
       "      <td>1.495356</td>\n",
       "      <td>0.326825</td>\n",
       "      <td>0.142612</td>\n",
       "      <td>0.253040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5521</td>\n",
       "      <td>1.620178</td>\n",
       "      <td>0.229202</td>\n",
       "      <td>0.118522</td>\n",
       "      <td>0.171020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4694</td>\n",
       "      <td>1.653001</td>\n",
       "      <td>0.264007</td>\n",
       "      <td>0.178016</td>\n",
       "      <td>0.265437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2826</td>\n",
       "      <td>1.782049</td>\n",
       "      <td>0.238540</td>\n",
       "      <td>0.192408</td>\n",
       "      <td>0.259508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0654</td>\n",
       "      <td>1.954202</td>\n",
       "      <td>0.231749</td>\n",
       "      <td>0.181121</td>\n",
       "      <td>0.239160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8878</td>\n",
       "      <td>2.034287</td>\n",
       "      <td>0.256367</td>\n",
       "      <td>0.207232</td>\n",
       "      <td>0.276509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>2.255198</td>\n",
       "      <td>0.243633</td>\n",
       "      <td>0.198625</td>\n",
       "      <td>0.263631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6571</td>\n",
       "      <td>2.271823</td>\n",
       "      <td>0.252122</td>\n",
       "      <td>0.196945</td>\n",
       "      <td>0.256862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6078</td>\n",
       "      <td>2.381421</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.188784</td>\n",
       "      <td>0.251957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5794</td>\n",
       "      <td>2.364112</td>\n",
       "      <td>0.242784</td>\n",
       "      <td>0.192908</td>\n",
       "      <td>0.256952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss      loss  accuracy  macro_f1  weighted_f1\n",
       "0      1.5691  1.495356  0.326825  0.142612     0.253040\n",
       "1      1.5521  1.620178  0.229202  0.118522     0.171020\n",
       "2      1.4694  1.653001  0.264007  0.178016     0.265437\n",
       "3      1.2826  1.782049  0.238540  0.192408     0.259508\n",
       "4      1.0654  1.954202  0.231749  0.181121     0.239160\n",
       "5      0.8878  2.034287  0.256367  0.207232     0.276509\n",
       "6      0.7500  2.255198  0.243633  0.198625     0.263631\n",
       "7      0.6571  2.271823  0.252122  0.196945     0.256862\n",
       "8      0.6078  2.381421  0.236842  0.188784     0.251957\n",
       "9      0.5794  2.364112  0.242784  0.192908     0.256952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 2.034287452697754,\n",
       " '0_precision': 0.5201793721973094,\n",
       " '0_recall': 0.2230769230769231,\n",
       " '0_f1-score': 0.3122476446837147,\n",
       " '0_support': 520.0,\n",
       " '1_precision': 0.266839378238342,\n",
       " '1_recall': 0.28690807799442897,\n",
       " '1_f1-score': 0.276510067114094,\n",
       " '1_support': 359.0,\n",
       " '2_precision': 0.22676579925650558,\n",
       " '2_recall': 0.2747747747747748,\n",
       " '2_f1-score': 0.2484725050916497,\n",
       " '2_support': 222.0,\n",
       " '3_precision': 0.07722007722007722,\n",
       " '3_recall': 0.3076923076923077,\n",
       " '3_f1-score': 0.12345679012345678,\n",
       " '3_support': 65.0,\n",
       " '4_precision': 0.04878048780487805,\n",
       " '4_recall': 0.16666666666666666,\n",
       " '4_f1-score': 0.07547169811320754,\n",
       " '4_support': 12.0,\n",
       " 'accuracy': 0.2563667232597623,\n",
       " 'macro_avg_precision': 0.22795702294342246,\n",
       " 'macro_avg_recall': 0.25182375004102026,\n",
       " 'macro_avg_f1-score': 0.20723174102522454,\n",
       " 'macro_avg_support': 1178.0,\n",
       " 'weighted_avg_precision': 0.3584340311019299,\n",
       " 'weighted_avg_recall': 0.2563667232597623,\n",
       " 'weighted_avg_f1-score': 0.2765086054288801,\n",
       " 'weighted_avg_support': 1178.0,\n",
       " 'runtime': 2.1134,\n",
       " 'samples_per_second': 557.384,\n",
       " 'steps_per_second': 3.785,\n",
       " 'epoch': 6.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adaf82f5d20c4cd691984f6199455663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_0</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.138818</td>\n",
       "      <td>0.521852</td>\n",
       "      <td>0.193484</td>\n",
       "      <td>0.140729</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.285422</td>\n",
       "      <td>0.192373</td>\n",
       "      <td>0.497032</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028479</td>\n",
       "      <td>0.133697</td>\n",
       "      <td>0.500870</td>\n",
       "      <td>0.228421</td>\n",
       "      <td>0.108533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.651193</td>\n",
       "      <td>0.125625</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.087786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212109</td>\n",
       "      <td>0.189855</td>\n",
       "      <td>0.173796</td>\n",
       "      <td>0.106447</td>\n",
       "      <td>0.317792</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_0   score_1   score_2   score_3   score_4  labels\n",
       "0  0.138818  0.521852  0.193484  0.140729  0.005116       1\n",
       "1  0.014776  0.285422  0.192373  0.497032  0.010396       3\n",
       "2  0.028479  0.133697  0.500870  0.228421  0.108533       2\n",
       "3  0.651193  0.125625  0.105413  0.029984  0.087786       0\n",
       "4  0.212109  0.189855  0.173796  0.106447  0.317792       4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_classification(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216440a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detection(full_dataset: bool, threshold: float | None):\n",
    "    set_random_seeds()\n",
    "    model, tokenizer = detection_model(model_name)\n",
    "    arguments = TrainingArguments(\n",
    "        num_train_epochs=4,\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        **default_arguments,\n",
    "    )\n",
    "    train_logs, metrics = train_detection(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        arguments,\n",
    "        full_dataset=full_dataset,\n",
    "        threshold=threshold,  # Threshold para predecir humor más alto requiere máyor probabiliad (0.75 es un buen valor pero depende del modelo)\n",
    "        save_path=f\"{save_path}/detection\" if full_dataset else None,\n",
    "    )\n",
    "    display(train_logs)\n",
    "    display(metrics)\n",
    "    if not full_dataset:\n",
    "        display(test_detection(model, tokenizer, arguments, threshold=threshold))\n",
    "    display(\n",
    "        predict_detection(model, tokenizer, prompts, arguments, threshold=threshold)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a016b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cd71acbd0c422c8ee5ee52b19649d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81b1558de584c58a30e293c714b7a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1991 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [640/640 02:25, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>0 Precision</th>\n",
       "      <th>0 Recall</th>\n",
       "      <th>0 F1-score</th>\n",
       "      <th>0 Support</th>\n",
       "      <th>1 Precision</th>\n",
       "      <th>1 Recall</th>\n",
       "      <th>1 F1-score</th>\n",
       "      <th>1 Support</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Avg Precision</th>\n",
       "      <th>Macro Avg Recall</th>\n",
       "      <th>Macro Avg F1-score</th>\n",
       "      <th>Macro Avg Support</th>\n",
       "      <th>Weighted Avg Precision</th>\n",
       "      <th>Weighted Avg Recall</th>\n",
       "      <th>Weighted Avg F1-score</th>\n",
       "      <th>Weighted Avg Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.527266</td>\n",
       "      <td>0.833080</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>0.745924</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.906621</td>\n",
       "      <td>0.850996</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>0.817441</td>\n",
       "      <td>0.790949</td>\n",
       "      <td>0.798460</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>0.814574</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>0.808091</td>\n",
       "      <td>1991.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.518757</td>\n",
       "      <td>0.825963</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.764861</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.896435</td>\n",
       "      <td>0.855754</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.821195</td>\n",
       "      <td>0.822284</td>\n",
       "      <td>0.804306</td>\n",
       "      <td>0.810307</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>0.821609</td>\n",
       "      <td>0.821195</td>\n",
       "      <td>0.818639</td>\n",
       "      <td>1991.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.655579</td>\n",
       "      <td>0.864322</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.731915</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>0.786944</td>\n",
       "      <td>0.931239</td>\n",
       "      <td>0.853033</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.810146</td>\n",
       "      <td>0.825633</td>\n",
       "      <td>0.782963</td>\n",
       "      <td>0.792474</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>0.818540</td>\n",
       "      <td>0.810146</td>\n",
       "      <td>0.803576</td>\n",
       "      <td>1991.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>0.722282</td>\n",
       "      <td>0.868825</td>\n",
       "      <td>0.627306</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>0.784188</td>\n",
       "      <td>0.934635</td>\n",
       "      <td>0.852827</td>\n",
       "      <td>1178.000000</td>\n",
       "      <td>0.809141</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>0.780971</td>\n",
       "      <td>0.790699</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>0.818748</td>\n",
       "      <td>0.809141</td>\n",
       "      <td>0.802089</td>\n",
       "      <td>1991.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3893</td>\n",
       "      <td>0.527266</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>0.798460</td>\n",
       "      <td>0.808091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2868</td>\n",
       "      <td>0.518757</td>\n",
       "      <td>0.821195</td>\n",
       "      <td>0.810307</td>\n",
       "      <td>0.818639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1971</td>\n",
       "      <td>0.655579</td>\n",
       "      <td>0.810146</td>\n",
       "      <td>0.792474</td>\n",
       "      <td>0.803576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.722282</td>\n",
       "      <td>0.809141</td>\n",
       "      <td>0.790699</td>\n",
       "      <td>0.802089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss      loss  accuracy  macro_f1  weighted_f1\n",
       "0      0.3893  0.527266  0.812155  0.798460     0.808091\n",
       "1      0.2868  0.518757  0.821195  0.810307     0.818639\n",
       "2      0.1971  0.655579  0.810146  0.792474     0.803576\n",
       "3      0.1402  0.722282  0.809141  0.790699     0.802089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5187572240829468,\n",
       " '0_precision': 0.8259629101283881,\n",
       " '0_recall': 0.7121771217712177,\n",
       " '0_f1-score': 0.7648612945838837,\n",
       " '0_support': 813.0,\n",
       " '1_precision': 0.8186046511627907,\n",
       " '1_recall': 0.8964346349745331,\n",
       " '1_f1-score': 0.8557536466774717,\n",
       " '1_support': 1178.0,\n",
       " 'accuracy': 0.8211953792064289,\n",
       " 'macro_avg_precision': 0.8222837806455894,\n",
       " 'macro_avg_recall': 0.8043058783728754,\n",
       " 'macro_avg_f1-score': 0.8103074706306777,\n",
       " 'macro_avg_support': 1991.0,\n",
       " 'weighted_avg_precision': 0.8216093043717463,\n",
       " 'weighted_avg_recall': 0.8211953792064289,\n",
       " 'weighted_avg_f1-score': 0.8186388891425208,\n",
       " 'weighted_avg_support': 1991.0,\n",
       " 'runtime': 2.5951,\n",
       " 'samples_per_second': 767.208,\n",
       " 'steps_per_second': 5.395,\n",
       " 'epoch': 2.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b91dc5e4ba4767acd1ddd3a8c5bd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_0</th>\n",
       "      <th>score_1</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.412057</td>\n",
       "      <td>0.587943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.177811</td>\n",
       "      <td>0.822189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964855</td>\n",
       "      <td>0.035145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996777</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.996727</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_0   score_1  labels\n",
       "0  0.412057  0.587943       1\n",
       "1  0.177811  0.822189       1\n",
       "2  0.964855  0.035145       0\n",
       "3  0.996777  0.003222       0\n",
       "4  0.996727  0.003273       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_detection(True, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
